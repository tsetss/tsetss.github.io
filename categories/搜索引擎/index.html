<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>
搜索引擎
       | 白天’s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="">
<meta name="author" content="">
<link rel="canonical" href="http://example.org/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css" integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://example.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://example.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://example.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://example.org/apple-touch-icon.png">
<link rel="mask-icon" href="http://example.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://example.org/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/index.xml">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="
搜索引擎
      " />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://example.org/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="
搜索引擎
      "/>
<meta name="twitter:description" content=""/>

</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://example.org/" accesskey="h" title="白天’s Blog (Alt + H)">白天’s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    
搜索引擎
      
  </h1>
</header>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2>百度暴风雨之前
    </h2>
  </header>
  <div class="entry-content">
    <p>经过6.22，6.28 百度事件之后，按目前来看，今晚要有大更新， 目前发现百度 site 命令波动相当的大，site:cn0314.com 从几百到几万一直在变化， 测试中华网也是 带 www 了只有几百而已，今天才发现，本 blog 百度排名已经消失，不知道什么时候会回来了，慢慢等待。。 准备洗洗睡了，明早起床看百度</p>
  </div>
  <footer class="entry-footer"><span title='2012-07-11 14:23:16 +0000 UTC'>July 11, 2012</span>&nbsp;·&nbsp;admin</footer>
  <a class="entry-link" aria-label="post link to 百度暴风雨之前" href="http://example.org/2012/07/11/e799bee5baa6e69ab4e9a38ee99ba8e4b98be5898d/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2>Sphinx Storage Engine in MySQL via FreeBSD Ports
    </h2>
  </header>
  <div class="entry-content">
    <p>系統：FreeBSD 7.1-RELEASE MySQL：5.1.30 Sphinx：0.9.8.1
mysql51-server.diff diff -Nur /usr/ports/databases/mysql51-server/Makefile mysql51-server/Makefile — /usr/ports/databases/mysql51-server/Makefile 2008-07-27 09:56:19.000000000 &#43;0100 &#43;&#43;&#43; mysql51-server/Makefile 2008-08-06 16:20:51.000000000 &#43;0100 @@ -60,6 &#43;60,16 @@ CONFIGURE_ARGS&#43;=–with-collation=${WITH_COLLATION} .endif &#43;# Sphinx Engine &#43;.if defined(WITH_SPHINXSE) &#43;SPHINX_PORT?= textproc/sphinxsearch &#43;SPHINX_WRKSRC= cd ${PORTSDIR}/${SPHINX_PORT} &amp;&amp; ${MAKE} -V WRKSRC &#43; &#43;EXTRACT_DEPENDS&#43;= ${NONEXISTENT}:${PORTSDIR}/${SPHINX_PORT}:extract &#43;RUN_DEPENDS&#43;= searchd:${PORTSDIR}/${SPHINX_PORT} &#43;USE_AUTOTOOLS&#43;= autoconf:262 automake:110 &#43;.endif &#43; .include .if ${ARCH} == “i386″ @@ -124,8 &#43;134,14 @@ @${ECHO} “ BUILD_STATIC=yes Build a static version of mysqld.” @${ECHO} “ (use it if you need even more speed)....</p>
  </div>
  <footer class="entry-footer"><span title='2009-03-23 16:59:55 +0000 UTC'>March 23, 2009</span>&nbsp;·&nbsp;admin</footer>
  <a class="entry-link" aria-label="post link to Sphinx Storage Engine in MySQL via FreeBSD Ports" href="http://example.org/2009/03/23/sphinx-storage-engine-in-mysql-via-freebsd-ports/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2>php &#43; xapian extension的安装
    </h2>
  </header>
  <div class="entry-content">
    <p>xapian是啥玩意?
xapian 是一个“Xapian 是一个开源概率论信息检索库，基于GPL发布。它是用C&#43;&#43;编写的，提供的绑定可以支持其它语言(支持Perl, Python, PHP, Java, and TCL )的开发。 Xapian 设计为一个高度可适应的工具集，可以让开发人员方便地为他们自己的应用程序增加高级索引和搜索功能。”
在网上找到这段介绍后,俺手痒痒就想试试xapian —- 一定要给php整个这东东上去.参考了若干文档以后,这就开始动手了(我的环境仍然是freebsd &#43; apache 2.2 &#43; php 5.1.2,apache和php原来就已经安装好):
1.下载xapian
cd /usr/local/src wget &lt;a href=&#34;http://www.oligarchy.co.uk/xapian/0.9.4/xapian-core-0.9.4.tar.gz&#34;&gt;http://www.oligarchy.co.uk/xapian/0.9.4/xapian-core-0.9.4.tar.gz&lt;/a&gt; wget &lt;a href=&#34;http://www.oligarchy.co.uk/xapian/0.9.4/xapian-bindings-0.9.4.tar.gz&#34;&gt;http://www.oligarchy.co.uk/xapian/0.9.4/xapian-bindings-0.9.4.tar.gz&lt;/a&gt; 前者是xapian的核心lib代码,后者是给其它语言调用的接口
2.安装Xapian-core
cd /usr/local/src tar xzvf xapian-core-0.9.4.tar.gz cd xapian-core-0.9.4 ./configure –prefix=/usr/local/xapian make make install 3.安装Xapian-bindings
cd /usr/local/src tar xzvf xapian-bindings-0.9.4.tar.gz cd xapian-bindings-0.9.4 ln -s /usr/local/xapian/bin/xapian-config /usr/local/bin/xapian-config #这里需要做个软连接,编译的时候需要用到 ./configure –without-python #我没用到python,就不编译了 make make install 进行到这一步,Xapian-bindings应该算是安装好了,但是不知道为何,编译好的xapian.so没有按说明文档所说的自动复制到php的extension目录,于是我手工完成这一步骤
cp php/.libs/xapian.so /usr/local/lib/php #/usr/local/lib/php是我在php.ini设置的extension目录 然后修改php.ini extension_dir = “/usr/local/lib/php/” #没有就加上 extension=xapian....</p>
  </div>
  <footer class="entry-footer"><span title='2006-12-11 05:56:16 +0000 UTC'>December 11, 2006</span>&nbsp;·&nbsp;admin</footer>
  <a class="entry-link" aria-label="post link to php &#43; xapian extension的安装" href="http://example.org/2006/12/11/php-xapian-extensione79a84e5ae89e8a385/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2>Google文件系统
    </h2>
  </header>
  <div class="entry-content">
    <p>转载自互连网 Google文件系统
GFS是一个可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。它运行于廉价的普通硬件上，但可以提供容错功能。它可以给大量的用户提供总体性能较高的服务。 1、设计概览 （1）设计想定 GFS与过去的分布式文件系统有很多相同的目标，但GFS的设计受到了当前及预期的应用方面的工作量及技术环境的驱动，这反映了它与早期的文件系统明显不同的设想。这就需要对传统的选择进行重新检验并进行完全不同的设计观点的探索。 GFS与以往的文件系统的不同的观点如下： 1、部件错误不再被当作异常，而是将其作为常见的情况加以处理。因为文件系统由成百上千个用于存储的机器构成，而这些机器是由廉价的普通部件组成并被大量的客户机访问。部件的数量和质量使得一些机器随时都有可能无法工作并且有一部分还可能无法恢复。所以实时地监控、错误检测、容错、自动恢复对系统来说必不可少。 2、按照传统的标准，文件都非常大。长度达几个GB的文件是很平常的。每个文件通常包含很多应用对象。当经常要处理快速增长的、包含数以万计的对象、长度达TB的数据集时，我们很难管理成千上万的KB规模的文件块，即使底层文件系统提供支持。因此，设计中操作的参数、块的大小必须要重新考虑。对大型的文件的管理一定要能做到高效，对小型的文件也必须支持，但不必优化。 3、大部分文件的更新是通过添加新数据完成的，而不是改变已存在的数据。在一个文件中随机的操作在实践中几乎不存在。一旦写完，文件就只可读，很多数据都有这些特性。一些数据可能组成一个大仓库以供数据分析程序扫描。有些是运行中的程序连续产生的数据流。有些是档案性质的数据，有些是在某个机器上产生、在另外一个机器上处理的中间数据。由于这些对大型文件的访问方式，添加操作成为性能优化和原子性保证的焦点。而在客户机中缓存数据块则失去了吸引力。 4、工作量主要由两种读操作构成：对大量数据的流方式的读操作和对少量数据的随机方式的读操作。在前一种读操作中，可能要读几百KB，通常达 1MB和更多。来自同一个客户的连续操作通常会读文件的一个连续的区域。随机的读操作通常在一个随机的偏移处读几个KB。性能敏感的应用程序通常将对少量数据的读操作进行分类并进行批处理以使得读操作稳定地向前推进，而不要让它来来回回的读。 5、工作量还包含许多对大量数据进行的、连续的、向文件添加数据的写操作。所写的数据的规模和读相似。一旦写完，文件很少改动。在随机位置对少量数据的写操作也支持，但不必非常高效。 6、系统必须高效地实现定义完好的大量客户同时向同一个文件的添加操作的语义。 （2）系统接口 GFS提供了一个相似地文件系统界面，虽然它没有向POSIX那样实现标准的API。文件在目录中按层次组织起来并由路径名标识。 （3）体系结构： 一个GFS集群由一个master和大量的chunkserver构成，并被许多客户（Client）访问。如图1所示。Master和 chunkserver通常是运行用户层服务进程的Linux机器。只要资源和可靠性允许，chunkserver和client可以运行在同一个机器上。 文件被分成固定大小的块。每个块由一个不变的、全局唯一的64位的chunk－handle标识，chunk－handle是在块创建时由 master分配的。ChunkServer将块当作Linux文件存储在本地磁盘并可以读和写由chunk－handle和位区间指定的数据。出于可靠性考虑，每一个块被复制到多个chunkserver上。默认情况下，保存3个副本，但这可以由用户指定。 Master维护文件系统所以的元数据（metadata），包括名字空间、访问控制信息、从文件到块的映射以及块的当前位置。它也控制系统范围的活动，如块租约（lease）管理，孤儿块的垃圾收集，chunkserver间的块迁移。Master定期通过HeartBeat消息与每一个 chunkserver通信，给chunkserver传递指令并收集它的状态。 与每个应用相联的GFS客户代码实现了文件系统的API并与master和chunkserver通信以代表应用程序读和写数据。客户与master的交换只限于对元数据（metadata）的操作，所有数据方面的通信都直接和chunkserver联系。 客户和chunkserver都不缓存文件数据。因为用户缓存的益处微乎其微，这是由于数据太多或工作集太大而无法缓存。不缓存数据简化了客户程序和整个系统，因为不必考虑缓存的一致性问题。但用户缓存元数据（metadata）。Chunkserver也不必缓存文件，因为块时作为本地文件存储的。 （4）单master。 只有一个master也极大的简化了设计并使得master可以根据全局情况作出先进的块放置和复制决定。但是我们必须要将master对读和写的参与减至最少，这样它才不会成为系统的瓶颈。Client从来不会从master读和写文件数据。Client只是询问master它应该和哪个 chunkserver联系。Client在一段限定的时间内将这些信息缓存，在后续的操作中Client直接和chunkserver交互。 以图1解释一下一个简单的读操作的交互。 1、client使用固定的块大小将应用程序指定的文件名和字节偏移转换成文件的一个块索引（chunk index）。 2、给master发送一个包含文件名和块索引的请求。 3、master回应对应的chunk handle和副本的位置（多个副本）。 4、client以文件名和块索引为键缓存这些信息。（handle和副本的位置）。 5、Client 向其中一个副本发送一个请求，很可能是最近的一个副本。请求指定了chunk handle（chunkserver以chunk handle标识chunk）和块内的一个字节区间。 6、除非缓存的信息不再有效（cache for a limited time）或文件被重新打开，否则以后对同一个块的读操作不再需要client和master间的交互。 通常Client可以在一个请求中询问多个chunk的地址，而master也可以很快回应这些请求。 （5）块规模： 块规模是设计中的一个关键参数。我们选择的是64MB，这比一般的文件系统的块规模要大的多。每个块的副本作为一个普通的Linux文件存储，在需要的时候可以扩展。 块规模较大的好处有： 1、减少client和master之间的交互。因为读写同一个块只是要在开始时向master请求块位置信息。对于读写大型文件这种减少尤为重要。即使对于访问少量数据的随机读操作也可以很方便的为一个规模达几个TB的工作集缓缓存块位置信息。 2、Client在一个给定的块上很可能执行多个操作，和一个chunkserver保持较长时间的TCP连接可以减少网络负载。 3、这减少了master上保存的元数据（metadata）的规模，从而使得可以将metadata放在内存中。这又会带来一些别的好处。 不利的一面： 一个小文件可能只包含一个块，如果很多Client访问改文件的话，存储这些块的chunkserver将成为访问的热点。但在实际应用中，应用程序通常顺序地读包含多个块的文件，所以这不是一个主要问题。 （6）元数据（metadata）： master存储了三中类型的metadata：文件的名字空间和块的名字空间，从文件到块的映射，块的副本的位置。所有的metadata都放在内存中。前两种类型的metadata通过向操作日志登记修改而保持不变，操作日志存储在master的本地磁盘并在几个远程机器上留有副本。使用日志使得我们可以很简单地、可靠地更新master的状态，即使在master崩溃的情况下也不会有不一致的问题。相反，mater在每次启动以及当有 chuankserver加入的时候询问每个chunkserver的所拥有的块的情况。 A、内存数据结构： 因为metadata存储在内存中，所以master的操作很快。进一步，master可以轻易而且高效地定期在后台扫描它的整个状态。这种定期地扫描被用于实现块垃圾收集、chunkserver出现故障时的副本复制、为平衡负载和磁盘空间而进行的块迁移。 这种方法的一个潜在的问题就是块的数量也即整个系统的容量是否受限与master的内存。实际上，这并不是一个严重的问题。Master为每个 64MB的块维护的metadata不足64个字节。除了最后一块，文件所有的块都是满的。类似的，每个文件的名字空间数据也不足64个字节，因为文件名是以一种事先确定的压缩方式存储的.如果要支持更大的文件系统，那么增加一些内存的方法对于我们将元数据（metadata）保存在内存种所获得的简单性、可靠性、高性能和灵活性来说，这只是一个很小的代价。 B、块位置： master并不为chunkserver所拥有的块的副本的保存一个不变的记录。它在启动时通过简单的查询来获得这些信息。Master可以保持这些信息的更新，因为它控制所有块的放置并通过HeartBeat消息来监控chunkserver的状态。 这样做的好处：因为chunkserver可能加入或离开集群、改变路径名、崩溃、重启等，一个集群重有成百个server，这些事件经常发生，这种方法就排除了master与chunkserver之间的同步问题。 另一个原因是：只有chunkserver才能确定它自己到底有哪些块，由于错误，chunkserver中的一些块可能会很自然的消失，这样在master中就没有必要为此保存一个不变的记录。 C、操作日志： 操作日志包含了对metadata所作的修改的历史记录。它作为逻辑时间线定义了并发操作的执行顺序。文件、块以及它们的版本号都由它们被创建时的逻辑时间而唯一地、永久地被标识。 操作日志是如此的重要，我们必须要将它可靠地保存起来，并且只有在metadata的改变固定下来之后才将变化呈现给用户。所以我们将操作日志复制到数个远程的机器上，并且只有在将相应的日志记录写到本地和远程的磁盘上之后才回答用户的请求。 Master可以用操作日志来恢复它的文件系统的状态。为了将启动时间减至最小，日志就必须要比较小。每当日志的长度增长到超过一定的规模后，master就要检查它的状态，它可以从本地磁盘装入最近的检查点来恢复状态。 创建一个检查点比较费时，master的内部状态是以一种在创建一个检查点时并不耽误即将到来的修改操作的方式来组织的。Master切换到一个新的日子文件并在一个单独的线程中创建检查点。这个新的检查点记录了切换前所有的修改。在一个有数十万文件的集群中用一分钟左右就能完成。创建完后，将它写入本地和远程的磁盘。 （7）数据完整性 名字空间的修改必须是原子性的，它们只能有master处理：名字空间锁保证了操作的原子性和正确性，而master的操作日志在全局范围内定义了这些操作的顺序。 文件区间的状态在修改之后依赖于修改的类型，不论操作成功还是失败，也不论是不是并发操作。如果不论从哪个副本上读，所有的客户都看到同样的数据，那么文件的这个区域就是一致的。如果文件的区域是一致的并且用户可以看到修改操作所写的数据，那么它就是已定义的。如果修改是在没有并发写操作的影响下完成的，那么受影响的区域是已定义的，所有的client都能看到写的内容。成功的并发写操作是未定义但却是一致的。失败的修改将使区间处于不一致的状态。 Write操作在应用程序指定的偏移处写入数据，而record append操作使得数据（记录）即使在有并发修改操作的情况下也至少原子性的被加到GFS指定的偏移处，偏移地址被返回给用户。 在一系列成功的修改操作后，最后的修改操作保证文件区域是已定义的。GFS通过对所有的副本执行同样顺序的修改操作并且使用块版本号检测过时的副本（由于chunkserver退出而导致丢失修改）来做到这一点。 因为用户缓存了会位置信息，所以在更新缓存之前有可能从一个过时的副本中读取数据。但这有缓存的截止时间和文件的重新打开而受到限制。 在修改操作成功后，部件故障仍可以是数据受到破坏。GFS通过master和chunkserver间定期的handshake，借助校验和来检测对数据的破坏。一旦检测到，就从一个有效的副本尽快重新存储。只有在GFS检测前，所有的副本都失效，这个块才会丢失。 2、系统交互 （1）租约（lease）和修改顺序： （2）数据流 我们的目标是充分利用每个机器的网络带宽，避免网络瓶颈和延迟 为了有效的利用网络，我们将数据流和控制流分离。数据是以流水线的方式在选定的chunkerserver链上线性的传递的。每个机器的整个对外带宽都被用作传递数据。为避免瓶颈，每个机器在收到数据后，将它收到数据尽快传递给离它最近的机器。 （3）原子性的record Append： GFS提供了一个原子性的添加操作：record append。在传统的写操作中，client指定被写数据的偏移位置，向同一个区间的并发的写操作是不连续的：区间有可能包含来自多个client的数据碎片。在record append中， client只是指定数据。GFS在其选定的偏移出将数据至少原子性的加入文件一次，并将偏移返回给client。 在分布式的应用中，不同机器上的许多client可能会同时向一个文件执行添加操作，添加操作被频繁使用。如果用传统的write操作，可能需要额外的、复杂的、开销较大的同步，例如通过分布式锁管理。在我们的工作量中，这些文件通常以多个生产者单个消费者队列的方式或包含从多个不同 client的综合结果。 Record append和前面讲的write操作的控制流差不多，只是在primary上多了一些逻辑判断。首先，client将数据发送到文件最后一块的所有副本上。然后向primary发送请求。Primary检查添加操作是否会导致该块超过最大的规模（64M）。如果这样，它将该块扩充到最大规模，并告诉其它副本做同样的事，同时通知client该操作需要在下一个块上重新尝试。如果记录满足最大规模的要求，primary就会将数据添加到它的副本上，并告诉其它的副本在在同样的偏移处写数据，最后primary向client报告写操作成功。如果在任何一个副本上record append操作失败，client将重新尝试该操作。这时候，同一个块的副本可能包含不同的数据，因为有的可能复制了全部的数据，有的可能只复制了部分。GFS不能保证所有的副本每个字节都是一样的。它只保证每个数据作为一个原子单元被写过至少一次。这个是这样得出的：操作要是成功，数据必须在所有的副本上的同样的偏移处被写过。进一步，从这以后，所有的副本至少和记录一样长，所以后续的记录将被指定到更高的偏移处或者一个不同的块上，即使另一个副本成了primary。根据一致性保证，成功的record append操作的区间是已定义的。而受到干扰的区间是不一致的。 （4）快照（snapshot） 快照操作几乎在瞬间构造一个文件和目录树的副本，同时将正在进行的其他修改操作对它的影响减至最小。 我们使用copy-on-write技术来实现snapshot。当master受到一个snapshot请求时，它首先将要snapshot的文件上块上的lease。这使得任何一个向这些块写数据的操作都必须和master交互以找到拥有lease的副本。这就给master一个创建这个块的副本的机会。 副本被撤销或终止后，master在磁盘上登记执行的操作，然后复制源文件或目录树的metadata以对它的内存状态实施登记的操作。这个新创建的snapshot文件和源文件（其metadata）指向相同的块（chunk）。 Snapshot之后，客户第一次向chunk c写的时候，它发一个请求给master以找到拥有lease的副本。Master注意到chunk c的引用记数比1大，它延迟对用户的响应，选择一个chunk handle C’,然后要求每一有chunk c的副本的chunkserver创建一个块C’。每个chunkserver在本地创建chunk C’避免了网络开销。从这以后和对别的块的操作没有什么区别。 3、MASTER操作 MASTER执行所有名字空间的操作，除此之外，他还在系统范围管理数据块的复制：决定数据块的放置方案，产生新数据块并将其备份，和其他系统范围的操作协同来确保数据备份的完整性，在所有的数据块服务器之间平衡负载并收回没有使用的存储空间。 3....</p>
  </div>
  <footer class="entry-footer"><span title='2006-05-26 18:22:22 +0000 UTC'>May 26, 2006</span>&nbsp;·&nbsp;admin</footer>
  <a class="entry-link" aria-label="post link to Google文件系统" href="http://example.org/2006/05/26/googlee69687e4bbb6e7b3bbe7bb9f/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2>相似度的问题
    </h2>
  </header>
  <div class="entry-content">
    <p>贝叶斯算法介绍 一． 贝叶斯过滤算法的基本步骤
收集大量的垃圾邮件和非垃圾邮件，建立垃圾邮件集和非垃圾邮件集。 提取邮件主题和邮件体中的独立字串例如 ABC32，￥234等作为TOKEN串并统计提取出的TOKEN串出现的次数即字频。按照上述的方法分别处理垃圾邮件集和非垃圾邮件集中的所有邮件。 每一个邮件集对应一个哈希表，hashtable_good对应非垃圾邮件集而hashtable_bad对应垃圾邮件集。表中存储TOKEN串到字频的映射关系。 计算每个哈希表中TOKEN串出现的概率P=（某TOKEN串的字频）/（对应哈希表的长度） 综合考虑hashtable_good和hashtable_bad，推断出当新来的邮件中出现某个TOKEN串时，该新邮件为垃圾邮件的概率。数学表达式为： A事件—-邮件为垃圾邮件; t1,t2 …….tn代表TOKEN串 则P（A|ti）表示在邮件中出现TOKEN串ti时，该邮件为垃圾邮件的概率。 设 P1（ti）=（ti在hashtable_good中的值） P2（ti）=（ti在hashtable_ bad中的值） 则 P（A|ti）= P1（ti）/[（P1（ti）&#43; P2（ti）]； 建立新的哈希表 hashtable_probability存储TOKEN串ti到P（A|ti）的映射 至此，垃圾邮件集和非垃圾邮件集的学习过程结束。根据建立的哈希表 hashtable_probability可以估计一封新到的邮件为垃圾邮件的可能性。 当新到一封邮件时，按照步骤2）生成TOKEN串。查询hashtable_probability得到该TOKEN 串的键值。 假设由该邮件共得到N个TOKEN串，t1,t2…….tn, hashtable_probability中对应的值为P1，P2，。。。。。。PN， P(A|t1 ,t2, t3……tn)表示在邮件中同时出现多个TOKEN串t1,t2…….tn时，该邮件为垃圾邮件的概率。 由复合概率公式可得 P(A|t1 ,t2, t3……tn)=（P1P2。。。。PN）/[P1P2。。。。。PN&#43;（1-P1）（1-P2）。。。（1-PN）] 当P(A|t1 ,t2, t3……tn)超过预定阈值时，就可以判断邮件为垃圾邮件。 二． 贝叶斯过滤算法举例
例如：一封含有“法轮功”字样的垃圾邮件 A 和 一封含有“法律”字样的非垃圾邮件B 根据邮件A生成hashtable_ bad，该哈希表中的记录为 法：1次 轮：1次 功：1次 计算得在本表中： 法出现的概率为0。3 轮出现的概率为0。3 功出现的概率为0。3 根据邮件B生成hashtable_good，该哈希表中的记录为： 法：1 律：1 计算得在本表中： 法出现的概率为0。5 律出现的概率为0。5 综合考虑两个哈希表，共有四个TOKEN串： 法 轮 功 律 当邮件中出现“法”时，该邮件为垃圾邮件的概率为： P=0。3/（0。3&#43;0。5）=0。375 出现“轮”时： P=0。3/（0。3&#43;0）=1 出现“功“时： P=0。3/（0。3&#43;0）=1 出现“律”时 P=0/（0&#43;0。5）=0； 由此可得第三个哈希表：hashtable_probability 其数据为： 法：0。375 轮：1 功：1 律：0...</p>
  </div>
  <footer class="entry-footer"><span title='2006-05-23 14:20:21 +0000 UTC'>May 23, 2006</span>&nbsp;·&nbsp;admin</footer>
  <a class="entry-link" aria-label="post link to 相似度的问题" href="http://example.org/2006/05/23/e79bb8e4bcbce5baa6e79a84e997aee9a298/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2>配置aspseek建立强大的企业级搜索引擎
    </h2>
  </header>
  <div class="entry-content">
    <p>建立搜索引擎 没有全文检索，企业内部的知识管理系统就不能成为成功的系统。构建一个类似 GOOGLE 的全文检索系统的是否要花费巨大呢？看看 Google 的搜索引擎软件目录吧。
我对其中的两个开放源码的搜索引擎进行了测试。htdig 是一个不错的搜索引擎软件，可惜不支持中文的检索；ASPseek 接着走入我的视线，这个软件对中文的支持非常之好，就连CGI的界面、CGI传递参数都和 GOOGLE 非常类似。
ASPseek 由三个部分组成：前端的 cgi 程序 s.cgi 提供查询界面和返回查询结果；后端的守护程序 searchd 接收cgi程序的查询请求，执行数据库查询，返回结果；后台数据库的维护则由程序 index 完成。
相关链接：
Google的搜索引擎软件目录
参见：http://dir.google.com/alpha/Top/ … net/Servers/Search/
另一个搜索引擎软件目录：
Search Tools for Web Sites and Intranets ：http://www.searchtools.com/tools/tools.html
ASPseek 网站
ASPseek.org：http://www.aspseek.org/
ASPseek论坛
关于ASPseek的求助信息，可以访问ASPseek论坛：http://forum.aspseek.org/。
2.1. 安装 ASPSeek ASPseek 安装过程比较简单，需要注意的是 ASPseek 的安装和运行需要先安装和配置 MySQL。下面是一般的安装过程（假设MySQL已经正确的安装在路径 /usr/local/mysql/ 下）：
root&gt;; tar zxvf aspseek-1.2.10.tar.gz root&gt;; cd aspseek-1.2.10 root&gt;; ./configure –with-mysql=/usr/local/mysql –prefix=/usr/local/aspseek root&gt;; make &amp;&amp; make install root&gt;; /usr/local/aspseek/sbin/aspseek-mysql-postinstall root&gt;; cp /usr/local/aspseek/bin/s....</p>
  </div>
  <footer class="entry-footer"><span title='2006-05-18 11:43:17 +0000 UTC'>May 18, 2006</span>&nbsp;·&nbsp;admin</footer>
  <a class="entry-link" aria-label="post link to 配置aspseek建立强大的企业级搜索引擎" href="http://example.org/2006/05/18/e9858de7bdaeaspseeke5bbbae7ab8be5bcbae5a4a7e79a84e4bc81e4b89ae7baa7e6909ce7b4a2e5bc95e6938e/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2>CLUCENE-0.9.10 索引与优化过程
    </h2>
  </header>
  <div class="entry-content">
    <p>一.文件索引过程 主要流程描述
IndexWriter writer(&#34;ndx&#34;, &amp;an;, true); writer.setMergeFactor(10); writer.setMinMergeDocs(10); Document *lpDoc = new Document; lpDoc-&gt;add(*new Field(&#34;content&#34;, &#34;This is demo content.&#34;, true, true, true) ); writer.addDocument(lpDoc); delete lpDoc; writer.close(); 下面描述该流程
1.IndexWriter writer(&#34;ndx&#34;, &amp;an;, true); directory = FSDirectory::getDirectory(&#34;ndx&#34;, true); 从一个全局的列表中取得一个对象 如果对象不存在，则新建一个并加入到列表中 主要目的是为了使用同一个目录只使用同一个FSDirectory对象 新建目录时删除该目录下所有文件级子目录 analyzer = an; 该对象由对象外部创建 segmentInfos = _CLNEW SegmentInfos; 建立一个SegmentInfos对象，该对象包含一个SegmentInfo对象的列表 建立时指定了SegmentInfo对象的列表并不在移除指针时删除SegmentInfo对象 一个SegmentInfo对象包括其名称(用于文件名前缀)和文档数 closeDir = true; 指定是否在索引对象关闭close时，是否同时调用目录的close函数 缺省为关闭目录对象 similarity = CL_NS(search)::Similarity::getDefault(); 取得缺省的文档分值score计算对象，如果不存在则建立 可以自己实现一个Similarity的继承类，然后用Similarity::setDefault方法设置成缺省的 变量Similarity* _defaultImpl用于保存缺省对象 ramDirectory = _CLNEW TransactionalRAMDirectory; 建立一个TransactionalRAMDirectory对象，该对象包含一个事务取消时的删除文件列表及恢复文件列表 同时还包含一个当前文件列表 恢复文件列表自动删除key和value，删除文件列表和当前文件列表则不自动删除 LuceneLock* newLock = directory-&gt;makeLock(&#34;write....</p>
  </div>
  <footer class="entry-footer"><span title='2006-05-14 02:34:27 +0000 UTC'>May 14, 2006</span>&nbsp;·&nbsp;admin</footer>
  <a class="entry-link" aria-label="post link to CLUCENE-0.9.10 索引与优化过程" href="http://example.org/2006/05/14/clucene-0910-e7b4a2e5bc95e4b88ee4bc98e58c96e8bf87e7a88b/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2>php &#43; clucene extension的安装
    </h2>
  </header>
  <div class="entry-content">
    <p>CLucene是SF上面的一个对Lucene(一个用Java写的全文检索引擎工具包)的移植,做为Lucene的C&#43;&#43;的重新实现，以带来更快的检索速度,但是一直还不stable.这里仅仅是尝试php&#43;clucene扩展的安装,具体应用先不管.
安装环境: Freebsd 6.0 &#43; apache 2.2 &#43; php 5.1.2
apache&#43;php的安装就不说了,网上一抓一大把,注意clucene扩展必须在php5以上才能安装.
首先安装clucene 1.下载clucene 直奔它的首页–clucene.sourceforge.net,下载clucene 0.9.10 2.编译clucene
tar xzvf clucene-0.9.10.tar.gz cd clucene-0.9.10 ./autogen.sh ./configure make 这样clucene就安装好了,为了让其它程序可以调用clucene,这里把编译好的lib放到系统lib目录下 cp src/.libs/libclucene.* /usr/local/lib cp src/CLucene.h /usr/local/include/ cp -r src/CLucene /usr/local/include/ 安装clucene php extension 1.下载clucene php extension 在pecl.php.net有下载,拖回来就是 http://pecl.php.net/package/clucene 2.编译clucene php extension tar xzvf clucene-0.0.9.tgz cd clucene-0.0.9 cp -r /usr/local/include/Clucene include/ #编译时要把clucene的include文件弄一份 cp -r /usr/local/include/Clucene.h include/ phpize ./configure make 编译完成,这里会生成一个clucene.so,我们把它放在php的extension目录下(没有就建一个),然后修改php.ini
加入 extension=clucene.so
重启apache之后看phpinfo
php&#43;clucene
至此安装就算完成了,demo嘛在examples目录下有一个,命令行调用方式(根据已有的index检索): php clucene....</p>
  </div>
  <footer class="entry-footer"><span title='2006-05-13 18:21:41 +0000 UTC'>May 13, 2006</span>&nbsp;·&nbsp;admin</footer>
  <a class="entry-link" aria-label="post link to php &#43; clucene extension的安装" href="http://example.org/2006/05/13/php-clucene-extensione79a84e5ae89e8a385/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2>于Lucene/XML的站内全文检索解决方案
    </h2>
  </header>
  <div class="entry-content">
    <p>关键词：Lucene xml xslt web site search engine 内容摘要： 为Lucene做一个通用XML接口一直是我最大的心愿：更方便的在WEB应用中嵌入全文检索功能
提供了XML的数据输入接口：适合将原有基于各种数据库的数据源导入到全文索引中，保证了数据源的平台无关性； 通过了基于XML的搜索结果输出：方便了通过XSLT进行前台的结果显示；
MySQL \ / JSP Oracle - DB - ==&gt; XML ==&gt; (Lucene Index) ==&gt; XML - ASP MSSQL / - PHP MS Word / \ / XHTML PDF / =XSLT=&gt; - TEXT \ XML \_________WebLucene__________/ 使用过程如下： 将数据用脚本导出成XML格式； 将XML数据源导入LUCENE索引； 从WEB界面得到XML结果输出，并通过XSLT生成HTML页面 站内全文检索的必要性
虽然大型搜索引擎的功能已经越来越强大了，很多站点都使用了Google的站内检索site:domain.com代替了自己的站内数据库“全文”检索。但依靠GOOGLE这样的大型搜索引擎做站内检索会有以下弊端：
数量有限：搜索引擎并不会深度遍历一个网站，而将网站所有的内容都索引进去，比如Google就喜欢静态网页，而且是最新更新的，而不喜欢带?的动态网页，Google甚至会定期将缺少入口的网站内容逐渐抛弃； 更新慢：搜索引擎针对站点的更新频率也是有一定周期的，很多内容需要一定时间后才能进入GOOGLE的索引：目前Google Dance的周期是21天左右； 内容不精确：搜索引擎需要通过页面内容提取技术将导航条，页头页尾等内容过滤掉，反而不如直接从后台数据库提取数据来得直接，这种摘要和排重机制是很难实现的； 无法控制输出：也许有更多的输出需求，按时间排序，按价格，按点击量，按类目过滤等 系统的搭建
下载： http://sourceforge.net/projects/weblucene/
XML数据源的导入：
只要数据源可以导出成3层的XML结构，就都可以用IndexRunner这个命令行工具导入：
比如从数据库导出：news_dump.xml 标题 作者 内容 2003-06-29 My Title chedong abc 2003-06-30 … IndexRunner -i news_dump....</p>
  </div>
  <footer class="entry-footer"><span title='2006-05-12 13:04:36 +0000 UTC'>May 12, 2006</span>&nbsp;·&nbsp;admin</footer>
  <a class="entry-link" aria-label="post link to 于Lucene/XML的站内全文检索解决方案" href="http://example.org/2006/05/12/e4ba8elucenexmle79a84e7ab99e58685e585a8e69687e6a380e7b4a2e8a7a3e586b3e696b9e6a188/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2>Lucene 全文检索实践
    </h2>
  </header>
  <div class="entry-content">
    <p></p>
  </div>
  <footer class="entry-footer"><span title='2006-05-12 12:22:24 +0000 UTC'>May 12, 2006</span>&nbsp;·&nbsp;admin</footer>
  <a class="entry-link" aria-label="post link to Lucene 全文检索实践" href="http://example.org/2006/05/12/lucene-e585a8e69687e6a380e7b4a2e5ae9ee8b7b5/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="http://example.org/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/page/2/">Next&nbsp;&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="http://example.org/">白天’s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
